{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission_stage_1.csv', 'test_stage_1.tsv', 'trees']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"data\"))\n",
    "import zipfile\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_feats = pickle.load(open('dataset/multi_inputs/test_feats.pkl', 'rb'))\n",
    "dev_feats = pickle.load(open('dataset/multi_inputs/dev_feats.pkl', 'rb'))\n",
    "val_feats = pickle.load(open('dataset/multi_inputs/val_feats.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['all', 'sum', 'mean', 'max'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_feats[0]['a'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_train_test_set(focus_on='max'):\n",
    "    \n",
    "    def prepare_data(feats, focus_on):\n",
    "        x, y = [], []\n",
    "        for feat in feats:\n",
    "            x.append(np.concatenate([feat['a'][focus_on], feat['b'][focus_on], feat['p']], axis=0))\n",
    "            y.append(feat['label'])\n",
    "        return x, y\n",
    "            \n",
    "    test_x, test_y = prepare_data(test_feats, focus_on)\n",
    "    val_x, val_y = prepare_data(val_feats, focus_on)\n",
    "    dev_x, dev_y = prepare_data(dev_feats, focus_on)\n",
    "    \n",
    "    train_x, train_y = np.concatenate([test_x, val_x], axis=0), np.concatenate([test_y, val_y], axis=0)\n",
    "    return (train_x, train_y), (dev_x, dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_x, train_y), (dev_x, dev_y) = generate_train_test_set('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_uuid": "29ba41d2570238ec22735909c76cd86c2742517c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend, models, layers, initializers, regularizers, constraints, optimizers\n",
    "from keras import callbacks as kc\n",
    "from keras import optimizers as ko\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import time\n",
    "\n",
    "\n",
    "dense_layer_sizes = [37]\n",
    "dropout_rate = 0.6\n",
    "learning_rate = 0.001\n",
    "n_fold = 5\n",
    "batch_size = 32\n",
    "epochs = 1000\n",
    "patience = 100\n",
    "# n_test = 100\n",
    "lambd = 0.1 # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "763ec8591474c45d6b065cad0c7efc2bbe9ad514",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mlp_model(input_shape):\n",
    "\tX_input = layers.Input(input_shape)\n",
    "\tX = layers.Dropout(dropout_rate, seed = 7)(X_input)\n",
    "\t# First dense layer\n",
    "\tX = layers.Dense(dense_layer_sizes[0], name = 'dense0')(X)\n",
    "\tX = layers.BatchNormalization(name = 'bn0')(X)\n",
    "\tX = layers.Activation('relu')(X)\n",
    "\tX = layers.Dropout(dropout_rate, seed = 7)(X)\n",
    "\n",
    "\t# Output layer\n",
    "\tX = layers.Dense(3, name = 'output', kernel_regularizer = regularizers.l2(lambd))(X)\n",
    "\tX = layers.Activation('softmax')(X)\n",
    "\n",
    "\t# Create model\n",
    "\tmodel = models.Model(input = X_input, output = X, name = \"classif_model\")\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "X_train, Y_train = train_x, to_categorical(train_y)\n",
    "X_development, Y_development = np.array(dev_x), to_categorical(dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Sat Apr 13 03:20:06 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zake7\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classif_model\", inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Sat Apr 13 03:24:04 2019\n",
      "Fold 2 started at Sat Apr 13 03:31:19 2019\n",
      "Fold 3 started at Sat Apr 13 03:36:25 2019\n",
      "Fold 4 started at Sat Apr 13 03:41:24 2019\n",
      "CV mean score: 0.5234, std: 0.0447.\n",
      "[0.48127582803266145, 0.46048753476395704, 0.5626410425670221, 0.5725375277047746, 0.5402216598068049]\n",
      "Test score: 0.4815043754691924\n"
     ]
    }
   ],
   "source": [
    "# Training and cross-validation\n",
    "test_num = 4\n",
    "for run in range(test_num):\n",
    "    folds = KFold(n_splits=n_fold, shuffle=True, random_state=3)\n",
    "    scores = []\n",
    "    oof = np.zeros_like(Y_train)\n",
    "    prediction = np.zeros_like(Y_development)\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X_train)):\n",
    "        # split training and validation data\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_tr, X_val = X_train[train_index], X_train[valid_index]\n",
    "        Y_tr, Y_val = Y_train[train_index], Y_train[valid_index]\n",
    "\n",
    "        # Define the model, re-initializing for each fold\n",
    "        classif_model = build_mlp_model([X_train.shape[1]])\n",
    "        classif_model.compile(optimizer = optimizers.Adam(lr = learning_rate), loss = \"categorical_crossentropy\")\n",
    "        callbacks = [kc.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights = True)]\n",
    "\n",
    "        # train the model\n",
    "        classif_model.fit(x = X_tr, y = Y_tr, epochs = epochs, batch_size = batch_size, callbacks = callbacks, validation_data = (X_val, Y_val), verbose = 0)\n",
    "\n",
    "        # make predictions on validation and test data\n",
    "        pred_valid = classif_model.predict(x = X_val, verbose = 0)\n",
    "        oof[valid_index] = pred_valid\n",
    "        pred = classif_model.predict(x = X_development, verbose = 0)\n",
    "\n",
    "        # oof[valid_index] = pred_valid.reshape(-1,)\n",
    "        scores.append(log_loss(Y_val, pred_valid))\n",
    "        prediction += pred\n",
    "\n",
    "    prediction /= n_fold\n",
    "\n",
    "    # Print CV scores, as well as score on the test data\n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    print(scores)\n",
    "    print(\"Test score:\", log_loss(Y_development, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV mean score: 0.5285, std: 0.0338.\n",
    "[0.4952458826401328, 0.48375502069637916, 0.5682628710749237, 0.5597365417256113, 0.5356817798765776]\n",
    "Test score: 0.49103962449882965\n",
    "    \n",
    "CV mean score: 0.5243, std: 0.0379.\n",
    "[0.5003560718592084, 0.4685565223567941, 0.5682392502662073, 0.563904224778733, 0.5206329654054942]\n",
    "Test score: 0.49357280478751636\n",
    "    \n",
    "CV mean score: 0.5240, std: 0.0383.\n",
    "[0.4950065191369652, 0.4670000282987749, 0.5668030280902658, 0.5613617074133851, 0.5296100813049671]\n",
    "Test score: 0.4927514025819255\n",
    "    \n",
    "CV mean score: 0.5263, std: 0.0378.\n",
    "[0.49447658181332393, 0.472486299146505, 0.5725461843181943, 0.5589639414076943, 0.5332190037439506]\n",
    "Test score: 0.4944068343992476    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV mean score: 0.5238, std: 0.0468.\n",
    "[0.47688187236489304, 0.46213150363347727, 0.5698529141631439, 0.5761041223376069, 0.5340085791760689]\n",
    "Test score: 0.48395181742742716\n",
    "    \n",
    "CV mean score: 0.5225, std: 0.0410.\n",
    "[0.48435351767456547, 0.46383921129004496, 0.5586745387855813, 0.5662293704637682, 0.5392278727089953]\n",
    "Test score: 0.48673919674764327\n",
    "    \n",
    "CV mean score: 0.5280, std: 0.0457.\n",
    "[0.47838048707321157, 0.4697366463747121, 0.5715442865168441, 0.5776206567589667, 0.542755629628534]\n",
    "Test score: 0.47883237509357784  \n",
    "    \n",
    "CV mean score: 0.5234, std: 0.0447.\n",
    "[0.48127582803266145, 0.46048753476395704, 0.5626410425670221, 0.5725375277047746, 0.5402216598068049]\n",
    "Test score: 0.4815043754691924        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV mean score: 0.5315, std: 0.0388.\n",
    "[0.48817598121504135, 0.48436255429821085, 0.5787604555612169, 0.5645790173302089, 0.5416744311974758]\n",
    "Test score: 0.50545762531316\n",
    "\n",
    "CV mean score: 0.5403, std: 0.0321.\n",
    "[0.4971414440332669, 0.5091939038344715, 0.5813902868192085, 0.5635956079994316, 0.5503828079077386]\n",
    "Test score: 0.5067319352220293\n",
    "    \n",
    "CV mean score: 0.5375, std: 0.0362.\n",
    "[0.4896285316412134, 0.49989288843345275, 0.5773998257683622, 0.5704335607287065, 0.5503486714648511]\n",
    "Test score: 0.5037706942331842\n",
    "\n",
    "CV mean score: 0.5369, std: 0.0376.\n",
    "[0.49427899776592293, 0.49054143951267815, 0.5830774302662529, 0.5633550574142361, 0.5533396635592407]\n",
    "Test score: 0.5078974904599308    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
